{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b04c9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd682bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set:\n",
      "{'max_samples': 10000, 'test_size': 0.1, 'max_length': 96, 'batch_size': 16, 'epochs': 2, 'base_model': 't5-small'}\n"
     ]
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    \"max_samples\": 10000,      \n",
    "    \"test_size\": 0.1,\n",
    "    \"max_length\": 96,        \n",
    "    \"batch_size\": 16,         \n",
    "    \"epochs\": 2,            \n",
    "    \"base_model\": \"t5-small\"\n",
    "}\n",
    "print(\"Configuration set:\")\n",
    "print(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b6da500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading and processing data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6367360285a46e59895d73979cff741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating ID map:   0%|          | 0/2811774 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nLoading and processing data...\")\n",
    "df = pd.read_csv('data.csv')\n",
    "tweet_id_map = {row['tweet_id']: row for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Creating ID map\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d6a7801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating valid conversation pairs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ca0c25b98142288f9270cb374ba1c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pairs generated:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "pairs = []\n",
    "valid_ids = set()\n",
    "\n",
    "print(\"\\nGenerating valid conversation pairs...\")\n",
    "with tqdm(total=CONFIG[\"max_samples\"], desc=\"Pairs generated\") as pbar:\n",
    "    for _, row in df.iterrows():\n",
    "        if row['inbound']:  # Only process customer messages\n",
    "            response_id = row['response_tweet_id']\n",
    "            if pd.notna(response_id):\n",
    "                response_ids = str(response_id).split(',')\n",
    "                for rid in response_ids:\n",
    "                    rid = rid.strip()\n",
    "                    if rid.isdigit():\n",
    "                        rid = int(rid)\n",
    "                        if rid in tweet_id_map:\n",
    "                            bot_row = tweet_id_map[rid]\n",
    "                            if not bot_row['inbound']:\n",
    "                                pairs.append((row['text'], bot_row['text']))\n",
    "                                valid_ids.add(rid)\n",
    "                                pbar.update(1)\n",
    "                                if len(pairs) >= CONFIG[\"max_samples\"]:\n",
    "                                    break\n",
    "                    if len(pairs) >= CONFIG[\"max_samples\"]:\n",
    "                        break\n",
    "        if len(pairs) >= CONFIG[\"max_samples\"]:\n",
    "            break\n",
    "\n",
    "# Ensure we have at least some data\n",
    "if not pairs:\n",
    "    raise ValueError(\"No valid conversation pairs found! Check data format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "746a8431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning text...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989a1eb4bd394a558ea480e44e5adb1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93dd7d27e558473eab15c8b8115c4a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'@\\w+|http\\S+', '', text)\n",
    "    return text.strip()[:200]  # Limit to 200 characters\n",
    "\n",
    "print(\"\\nCleaning text...\")\n",
    "inputs = [clean_text(p[0]) for p in tqdm(pairs)]\n",
    "targets = [clean_text(p[1]) for p in tqdm(pairs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6db030ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training samples: 9000\n",
      "Validation samples: 1000\n"
     ]
    }
   ],
   "source": [
    "train_inputs, val_inputs, train_targets, val_targets = train_test_split(\n",
    "    inputs, targets, test_size=CONFIG[\"test_size\"], random_state=42\n",
    ")\n",
    "print(f\"\\nTraining samples: {len(train_inputs)}\")\n",
    "print(f\"Validation samples: {len(val_inputs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a3308e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatDataset(Dataset):\n",
    "    def __init__(self, inputs, targets, tokenizer, max_len):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self): return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_enc = self.tokenizer(\n",
    "            self.inputs[idx],\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        target_enc = self.tokenizer(\n",
    "            self.targets[idx],\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': input_enc['input_ids'].squeeze(),\n",
    "            'attention_mask': input_enc['attention_mask'].squeeze(),\n",
    "            'labels': target_enc['input_ids'].squeeze()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf6cec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202650f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71386210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing model on cuda...\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nInitializing model on {device}...\")\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(CONFIG[\"base_model\"])\n",
    "model = T5ForConditionalGeneration.from_pretrained(CONFIG[\"base_model\"]).to(device)\n",
    "\n",
    "train_dataset = ChatDataset(train_inputs, train_targets, tokenizer, CONFIG[\"max_length\"])\n",
    "val_dataset = ChatDataset(val_inputs, val_targets, tokenizer, CONFIG[\"max_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f9f1918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devan\\anaconda3\\envs\\test\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=CONFIG[\"epochs\"],\n",
    "    per_device_train_batch_size=CONFIG[\"batch_size\"],\n",
    "    per_device_eval_batch_size=CONFIG[\"batch_size\"],\n",
    "    evaluation_strategy='epoch',\n",
    "    fp16=True,\n",
    "    logging_steps=50,\n",
    "    save_strategy='epoch',\n",
    "    report_to='none',\n",
    "    optim=\"adafactor\",  # Uses less memory\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2b0a3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1126' max='1126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1126/1126 03:11, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.984300</td>\n",
       "      <td>0.882171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.927700</td>\n",
       "      <td>0.854607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting training...\")\n",
    "train_result = trainer.train()\n",
    "print(\"\\nTraining completed!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2176f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model...\n",
      "Model saved to 'chatbot_model' directory\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSaving model...\")\n",
    "model.save_pretrained('chatbot_model')\n",
    "tokenizer.save_pretrained('chatbot_model')\n",
    "print(\"Model saved to 'chatbot_model' directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a618a6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devan\\anaconda3\\envs\\test\\Lib\\site-packages\\gradio\\chat_interface.py:338: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import gradio as gr\n",
    "import re\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('chatbot_model')\n",
    "model = T5ForConditionalGeneration.from_pretrained('chatbot_model')\n",
    "\n",
    "def clean_input(text):\n",
    "    return re.sub(r'@\\w+|http\\S+', '', text).strip()\n",
    "\n",
    "def respond(message, history):\n",
    "    message = clean_input(message)\n",
    "    inputs = tokenizer.encode(\n",
    "        message,\n",
    "        return_tensors='pt',\n",
    "        max_length=128,\n",
    "        truncation=True\n",
    "    )\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=160,\n",
    "        num_beams=5,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "gr.ChatInterface(respond).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
